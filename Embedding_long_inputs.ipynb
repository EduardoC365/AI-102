{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dcf874f6-d906-4bb7-83a2-f55f26b6bcae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Embedding texts that are longer than the model's maximum context length\n",
    "\n",
    "OpenAI's embedding models cannot embed text that exceeds a maximum length. The maximum length varies by model, and is measured by _tokens_, not string length. If you are unfamiliar with tokenization, check out [How to count tokens with tiktoken](How_to_count_tokens_with_tiktoken.ipynb).\n",
    "\n",
    "This notebook shows how to handle texts that are longer than a model's maximum context length. We'll demonstrate using embeddings from `text-embedding-3-small`, but the same ideas can be applied to other models and tasks. To learn more about embeddings, check out the [OpenAI Embeddings Guide](https://beta.openai.com/docs/guides/embeddings).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7f49e27-bd1f-4ac0-8531-78fab086ecf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Model context length\n",
    "\n",
    "First, we select the model and define a function to get embeddings from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8eec87f7-62be-4ed2-b85d-c535da0b2c5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting openai\n  Downloading openai-1.59.7-py3-none-any.whl (454 kB)\nCollecting typing-extensions<5,>=4.11\n  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\nCollecting httpx<1,>=0.23.0\n  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\nCollecting distro<2,>=1.7.0\n  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\nCollecting jiter<1,>=0.4.0\n  Downloading jiter-0.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\nCollecting sniffio\n  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\nCollecting tqdm>4\n  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\nCollecting pydantic<3,>=1.9.0\n  Downloading pydantic-2.10.5-py3-none-any.whl (431 kB)\nCollecting anyio<5,>=3.5.0\n  Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\nCollecting exceptiongroup>=1.0.2\n  Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\nRequirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.3)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2021.10.8)\nCollecting httpcore==1.*\n  Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\nCollecting h11<0.15,>=0.13\n  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\nCollecting annotated-types>=0.6.0\n  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\nCollecting pydantic-core==2.27.2\n  Downloading pydantic_core-2.27.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\nInstalling collected packages: typing-extensions, sniffio, h11, exceptiongroup, pydantic-core, httpcore, anyio, annotated-types, tqdm, pydantic, jiter, httpx, distro, openai\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 4.1.1\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f4b4bec6-88c8-4538-9d9d-00a0ea3fcd78\n    Can't uninstall 'typing-extensions'. No files were found to uninstall.\n  Attempting uninstall: distro\n    Found existing installation: distro 1.4.0\n    Not uninstalling distro at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f4b4bec6-88c8-4538-9d9d-00a0ea3fcd78\n    Can't uninstall 'distro'. No files were found to uninstall.\nSuccessfully installed annotated-types-0.7.0 anyio-4.8.0 distro-1.9.0 exceptiongroup-1.2.2 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.8.2 openai-1.59.7 pydantic-2.10.5 pydantic-core-2.27.2 sniffio-1.3.1 tqdm-4.67.1 typing-extensions-4.12.2\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nCollecting tiktoken\n  Downloading tiktoken-0.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\nRequirement already satisfied: requests>=2.26.0 in /databricks/python3/lib/python3.9/site-packages (from tiktoken) (2.27.1)\nCollecting regex>=2022.1.18\n  Downloading regex-2024.11.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (780 kB)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2021.10.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (1.26.9)\nInstalling collected packages: regex, tiktoken\nSuccessfully installed regex-2024.11.6 tiktoken-0.8.0\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nCollecting python-dotenv\n  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\nInstalling collected packages: python-dotenv\nSuccessfully installed python-dotenv-1.0.1\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai\n",
    "%pip install tiktoken\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9df50a0c-b651-46b6-8093-0a04d430f801",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import os\n",
    "import openai\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt, retry_if_not_exception_type\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://modeloai.openai.azure.com/\"\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"9dgOiNZtDzOZRaT6AICzzG0yWjAlYikPgIOq7DBc8FRaypJtAb2DJQQJ99BAACYeBjFXJ3w3AAABACOGu9nO\"\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "  api_version=\"2024-02-15-preview\"\n",
    ")\n",
    "\n",
    "EMBEDDING_MODEL = 'text-embedding-3-small'\n",
    "EMBEDDING_CTX_LENGTH = 1000\n",
    "EMBEDDING_ENCODING = 'cl100k_base'\n",
    "\n",
    "# let's make sure to not retry on an invalid request, because that is what we want to demonstrate\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6), retry=retry_if_not_exception_type(openai.BadRequestError))\n",
    "def get_embedding(text_or_tokens, model=EMBEDDING_MODEL):\n",
    "    return client.embeddings.create(input=text_or_tokens, model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b9034c9-aaea-4a3b-9476-5700ce0a44f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The `text-embedding-3-small` model has a context length of 8191 tokens with the `cl100k_base` encoding, and we can see that going over that limit causes an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ceb5014-7c16-4d3b-a5ea-f14d1beee98a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens, however you requested 10001 tokens (10001 in your prompt; 0 for the completion). Please reduce your prompt; or completion length.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n"
     ]
    }
   ],
   "source": [
    "long_text = 'AGI ' * 5000\n",
    "try:\n",
    "    get_embedding(long_text)\n",
    "except openai.BadRequestError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7115afcc-fcea-4bf0-9df0-ab8743e46593",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Clearly we want to avoid these errors, particularly when handling programmatically with a large number of embeddings. Yet, we still might be faced with texts that are longer than the maximum context length. Below we describe and provide recipes for the main approaches to handling these longer texts: (1) simply truncating the text to the maximum allowed length, and (2) chunking the text and embedding each chunk individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9da314f6-90d5-4608-b699-e633d9814ae5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Truncating the input text\n",
    "\n",
    "The simplest solution is to truncate the input text to the maximum allowed length. Because the context length is measured in tokens, we have to first tokenize the text before truncating it. The API accepts inputs both in the form of text or tokens, so as long as you are careful that you are using the appropriate encoding, there is no need to convert the tokens back into string form. Below is an example of such a truncation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54a2a7a7-8630-4896-ac8d-db5294cdd640",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def truncate_text_tokens(text, encoding_name=EMBEDDING_ENCODING, max_tokens=EMBEDDING_CTX_LENGTH):\n",
    "    \"\"\"Truncate a string to have `max_tokens` according to the given encoding.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    return encoding.encode(text)[:max_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39a86410-5301-4fe3-89b7-fe3f08459768",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Our example from before now works without error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e19f5c56-bbe3-4178-a31a-51875215fd44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[20]: 1536"
     ]
    }
   ],
   "source": [
    "truncated = truncate_text_tokens(long_text)\n",
    "len(get_embedding(truncated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b4c249e-19ae-4230-ad94-ca7ce560f528",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Chunking the input text\n",
    "\n",
    "Though truncation works, discarding potentially relevant text is a clear drawback. Another approach is to divide the input text into chunks and then embed each chunk individually. Then, we can either use the chunk embeddings separately, or combine them in some way, such as averaging (weighted by the size of each chunk).\n",
    "\n",
    "We will take a function from [Python's own cookbook](https://docs.python.org/3/library/itertools.html#itertools-recipes) that breaks up a sequence into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e85a2cb-35ec-4b2b-a91a-10d3ca63283c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def batched(iterable, n):\n",
    "    \"\"\"Batch data into tuples of length n. The last batch may be shorter.\"\"\"\n",
    "    # batched('ABCDEFG', 3) --> ABC DEF G\n",
    "    if n < 1:\n",
    "        raise ValueError('n must be at least one')\n",
    "    it = iter(iterable)\n",
    "    while (batch := tuple(islice(it, n))):\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8881c7ec-3974-4f9a-b855-b311c32301b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now we define a function that encodes a string into tokens and then breaks it up into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f54efb13-367f-43c5-9442-98fde9051539",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def chunked_tokens(text, encoding_name, chunk_length):\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    tokens = encoding.encode(text)\n",
    "    chunks_iterator = batched(tokens, chunk_length)\n",
    "    yield from chunks_iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "255ca9ba-8929-4105-b2ed-d9753a967048",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Finally, we can write a function that safely handles embedding requests, even when the input text is longer than the maximum context length, by chunking the input tokens and embedding each chunk individually. The `average` flag can be set to `True` to return the weighted average of the chunk embeddings, or `False` to simply return the unmodified list of chunk embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8156a95-678e-4ce1-b488-36a387a24510",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def len_safe_get_embedding(text, model=EMBEDDING_MODEL, max_tokens=EMBEDDING_CTX_LENGTH, encoding_name=EMBEDDING_ENCODING, average=True):\n",
    "    chunk_embeddings = []\n",
    "    chunk_lens = []\n",
    "    for chunk in chunked_tokens(text, encoding_name=encoding_name, chunk_length=max_tokens):\n",
    "        chunk_embeddings.append(get_embedding(chunk, model=model))\n",
    "        chunk_lens.append(len(chunk))\n",
    "\n",
    "    if average:\n",
    "        chunk_embeddings = np.average(chunk_embeddings, axis=0, weights=chunk_lens)\n",
    "        chunk_embeddings = chunk_embeddings / np.linalg.norm(chunk_embeddings)  # normalizes length to 1\n",
    "        chunk_embeddings = chunk_embeddings.tolist()\n",
    "    return chunk_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fce60cb4-ea26-4b88-a2d6-677485011ea5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Once again, we can now handle long input texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c142750f-04b8-493d-99a1-3b4d1fc29446",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting average=True gives us a single 1536-dimensional embedding vector for our long text.\nSetting average=False gives us 11 embedding vectors, one for each of the chunks.\n"
     ]
    }
   ],
   "source": [
    "average_embedding_vector = len_safe_get_embedding(long_text, average=True)\n",
    "chunks_embedding_vectors = len_safe_get_embedding(long_text, average=False)\n",
    "\n",
    "print(f\"Setting average=True gives us a single {len(average_embedding_vector)}-dimensional embedding vector for our long text.\")\n",
    "print(f\"Setting average=False gives us {len(chunks_embedding_vectors)} embedding vectors, one for each of the chunks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1148ab5-0be5-4ac0-b6f5-5af62e549f0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In some cases, it may make sense to split chunks on paragraph boundaries or sentence boundaries to help preserve the meaning of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01b68097-b2a5-458c-9945-9f20daeaebcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Ejercicio 1: Visualización de la Distribución de Tokens\n",
    "# Visualizar la distribución de tokens para diferentes textos largos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c58a4883-3515-4448-b2d1-e7269497816d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nRequirement already satisfied: tiktoken in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f4b4bec6-88c8-4538-9d9d-00a0ea3fcd78/lib/python3.9/site-packages (0.8.0)\nRequirement already satisfied: requests>=2.26.0 in /databricks/python3/lib/python3.9/site-packages (from tiktoken) (2.27.1)\nRequirement already satisfied: regex>=2022.1.18 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f4b4bec6-88c8-4538-9d9d-00a0ea3fcd78/lib/python3.9/site-packages (from tiktoken) (2024.11.6)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2021.10.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (1.26.9)\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57c7a204-ecb6-4d07-aec0-e09e4bf8b53b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n"
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "data:image/png;base64,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\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "image"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tiktoken\n",
    "\n",
    "texts = [\n",
    "    \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. \" * 200,\n",
    "    \"Data science is evolving rapidly with the use of machine learning and AI. \" * 150,\n",
    "    \"Azure OpenAI embeddings provide powerful tools for natural language processing. \" * 180\n",
    "]\n",
    "\n",
    "# Definir la codificación para GPT-3 o GPT-4 (se puede cambiar según el modelo que desees usar)\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# Codificar los textos y contar los tokens\n",
    "text_tokens = [encoding.encode(text) for text in texts]\n",
    "token_lengths = [len(tokens) for tokens in text_tokens]\n",
    "\n",
    "# Crear un gráfico de barras\n",
    "plt.bar([\"Text 1\", \"Text 2\", \"Text 3\"], token_lengths)\n",
    "plt.ylabel(\"Number of Tokens\")\n",
    "plt.title(\"Token Distribution Across Different Texts\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "409dd97a-7f38-4dcd-ad81-2421824f8d7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Ejercicio 2: Análisis de la Pérdida de Información con Truncado\n",
    "# Comparar embeddings con texto completo vs truncado y calcular la similitud coseno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77e7ca3c-7bd9-423e-8cd9-0cbddd8f31fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n  File \"/databricks/python/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<command-966348363540164>\", line 2, in <module>\n    from transformers import AutoTokenizer, AutoModel\n  File \"/databricks/python_shell/dbruntime/PythonPackageImportsInstrumentation/__init__.py\", line 171, in import_patch\n    original_result = python_builtin_import(name, globals, locals, fromlist, level)\nModuleNotFoundError: No module named 'transformers'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 1997, in showtraceback\n    stb = self.InteractiveTB.structured_traceback(\n  File \"/databricks/python/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1112, in structured_traceback\n    return FormattedTB.structured_traceback(\n  File \"/databricks/python/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1006, in structured_traceback\n    return VerboseTB.structured_traceback(\n  File \"/databricks/python/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 859, in structured_traceback\n    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n  File \"/databricks/python/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 812, in format_exception_as_a_whole\n    frames.append(self.format_record(r))\n  File \"/databricks/python/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 730, in format_record\n    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n  File \"/databricks/python/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/databricks/python/lib/python3.9/site-packages/stack_data/core.py\", line 698, in lines\n    pieces = self.included_pieces\n  File \"/databricks/python/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/databricks/python/lib/python3.9/site-packages/stack_data/core.py\", line 649, in included_pieces\n    pos = scope_pieces.index(self.executing_piece)\n  File \"/databricks/python/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/databricks/python/lib/python3.9/site-packages/stack_data/core.py\", line 628, in executing_piece\n    return only(\n  File \"/databricks/python/lib/python3.9/site-packages/executing/executing.py\", line 164, in only\n    raise NotOneValueFound('Expected one value, found 0')\nexecuting.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "<span class='ansi-red-fg'>ModuleNotFoundError</span>: No module named 'transformers'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Configuración del modelo y tokenizador\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].detach().numpy()\n",
    "\n",
    "def truncate_text_tokens(text, max_tokens=128):\n",
    "    tokens = tokenizer.encode(text, truncation=True, max_length=max_tokens, return_tensors=\"pt\")\n",
    "    return tokens\n",
    "\n",
    "text = \"Natural language processing models are essential for AI applications. \" * 300\n",
    "truncated_tokens = truncate_text_tokens(text)\n",
    "\n",
    "full_embedding = get_embedding(text)\n",
    "truncated_embedding = get_embedding(tokenizer.decode(truncated_tokens[0]))\n",
    "\n",
    "similarity = cosine_similarity([full_embedding], [truncated_embedding])[0][0]\n",
    "print(f\"Cosine Similarity between full and truncated embeddings: {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d606ef6-a2ba-4f86-b2db-b12e42a94508",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Ejercicio 3: Chunking Basado en Límites de Párrafos\n",
    "# Implementar una función que divida el texto por párrafos y embeba cada párrafo por separado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c888379d-68d9-440e-bb4a-b193049790f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-966348363540166>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparagraph_chunker\u001B[39m(text, max_tokens\u001B[38;5;241m=\u001B[39mEMBEDDING_CTX_LENGTH):\n",
       "\u001B[1;32m      2\u001B[0m     paragraphs \u001B[38;5;241m=\u001B[39m text\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m      3\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m []\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'EMBEDDING_CTX_LENGTH' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-966348363540166>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparagraph_chunker\u001B[39m(text, max_tokens\u001B[38;5;241m=\u001B[39mEMBEDDING_CTX_LENGTH):\n\u001B[1;32m      2\u001B[0m     paragraphs \u001B[38;5;241m=\u001B[39m text\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m []\n\n\u001B[0;31mNameError\u001B[0m: name 'EMBEDDING_CTX_LENGTH' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'EMBEDDING_CTX_LENGTH' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def paragraph_chunker(text, max_tokens=EMBEDDING_CTX_LENGTH):\n",
    "    paragraphs = text.split(\"\\n\\n\")\n",
    "    embeddings = []\n",
    "    for paragraph in paragraphs:\n",
    "        tokens = encoding.encode(paragraph)\n",
    "        if len(tokens) > max_tokens:\n",
    "            truncated = truncate_text_tokens(paragraph)\n",
    "            embeddings.append(get_embedding(truncated))\n",
    "        else:\n",
    "            embeddings.append(get_embedding(tokens))\n",
    "    return embeddings\n",
    "\n",
    "paragraph_text = \"\"\"\n",
    "Azure AI services are expanding rapidly.\\n\\n\n",
    "These services include natural language processing and computer vision.\\n\\n\n",
    "Embedding models allow for advanced text analytics.\\n\\n\n",
    "With Azure, developers can scale their applications easily.\n",
    "\"\"\"\n",
    "\n",
    "paragraph_embeddings = paragraph_chunker(paragraph_text)\n",
    "print(f\"Generated {len(paragraph_embeddings)} embeddings, one for each paragraph.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6610160-8ac0-4da0-a540-868bf0f7c923",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Ejercicio 4: Fusionar Embeddings de Chunks con Diferentes Estrategias\n",
    "# Comparar promedios simples vs ponderados por longitud del chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d89fb67-f1dc-4102-a0d4-c8e78e37f8a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between weighted and simple average embeddings: 1.0000\n"
     ]
    }
   ],
   "source": [
    "def merge_embeddings(embeddings, strategy=\"weighted\"):\n",
    "    if strategy == \"weighted\":\n",
    "        weights = [len(embedding) for embedding in embeddings]\n",
    "        merged = np.average(embeddings, axis=0, weights=weights)\n",
    "    elif strategy == \"simple\":\n",
    "        merged = np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid strategy. Choose 'weighted' or 'simple'.\")\n",
    "    return merged / np.linalg.norm(merged)\n",
    "\n",
    "merged_weighted = merge_embeddings(paragraph_embeddings, strategy=\"weighted\")\n",
    "merged_simple = #FIXME\n",
    "\n",
    "similarity = cosine_similarity([merged_weighted], [merged_simple])[0][0]\n",
    "print(f\"Cosine Similarity between weighted and simple average embeddings: {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d49575a-ef0c-43e1-98e4-a43950b0324f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Embedding_long_inputs",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "365536dcbde60510dc9073d6b991cd35db2d9bac356a11f5b64279a5e6708b97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
