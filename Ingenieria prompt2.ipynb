{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5241871a-cf92-4487-8dcf-1618f324a10c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# OpenAI Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25cc69a3-d104-47b1-866a-d5d29affc21c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Overview\n",
    "When making requests to OpenAI models, several parameters can be used to control the behavior and output of the model. \\\n",
    "Understanding these parameters helps in fine-tuning the responses to meet specific requirements, whether for generating text, answering questions, or any other use case.\n",
    "\n",
    "For more detailed examples, refer to the official documentation [Azure OpenAI Service](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fcc0f2d-5ae9-4b65-a06e-5cda5e2bbdd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting openai\n  Using cached openai-1.59.9-py3-none-any.whl (455 kB)\nCollecting typing-extensions<5,>=4.11\n  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\nCollecting httpx<1,>=0.23.0\n  Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\nCollecting distro<2,>=1.7.0\n  Using cached distro-1.9.0-py3-none-any.whl (20 kB)\nCollecting jiter<1,>=0.4.0\n  Using cached jiter-0.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\nCollecting sniffio\n  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\nCollecting tqdm>4\n  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\nCollecting pydantic<3,>=1.9.0\n  Using cached pydantic-2.10.5-py3-none-any.whl (431 kB)\nCollecting anyio<5,>=3.5.0\n  Using cached anyio-4.8.0-py3-none-any.whl (96 kB)\nCollecting exceptiongroup>=1.0.2\n  Using cached exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\nRequirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.3)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2021.10.8)\nCollecting httpcore==1.*\n  Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\nCollecting h11<0.15,>=0.13\n  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\nCollecting annotated-types>=0.6.0\n  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\nCollecting pydantic-core==2.27.2\n  Using cached pydantic_core-2.27.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\nInstalling collected packages: typing-extensions, sniffio, h11, exceptiongroup, pydantic-core, httpcore, anyio, annotated-types, tqdm, pydantic, jiter, httpx, distro, openai\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 4.1.1\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-319c5fe6-5141-4597-997e-e57255a8a436\n    Can't uninstall 'typing-extensions'. No files were found to uninstall.\n  Attempting uninstall: distro\n    Found existing installation: distro 1.4.0\n    Not uninstalling distro at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-319c5fe6-5141-4597-997e-e57255a8a436\n    Can't uninstall 'distro'. No files were found to uninstall.\nSuccessfully installed annotated-types-0.7.0 anyio-4.8.0 distro-1.9.0 exceptiongroup-1.2.2 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.8.2 openai-1.59.9 pydantic-2.10.5 pydantic-core-2.27.2 sniffio-1.3.1 tqdm-4.67.1 typing-extensions-4.12.2\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nCollecting tiktoken\n  Using cached tiktoken-0.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\nRequirement already satisfied: requests>=2.26.0 in /databricks/python3/lib/python3.9/site-packages (from tiktoken) (2.27.1)\nCollecting regex>=2022.1.18\n  Using cached regex-2024.11.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (780 kB)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2021.10.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (1.26.9)\nInstalling collected packages: regex, tiktoken\nSuccessfully installed regex-2024.11.6 tiktoken-0.8.0\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nCollecting python-dotenv\n  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\nInstalling collected packages: python-dotenv\nSuccessfully installed python-dotenv-1.0.1\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai\n",
    "%pip install tiktoken\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cd677a7-c913-4041-8d7e-c7cbec5a639f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Configura las credenciales directamente en el código\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://openai-tajamar-1.openai.azure.com/\"\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"ECFcJJqIk2YzAyaWsZ8QO9rMoHOZfr3EZYNDBgbBLGCTzJ1jmXR5JQQJ99BAACYeBjFXJ3w3AAABACOGpTLE\"\n",
    "\n",
    "# Crear el cliente con las credenciales\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    api_version=\"2024-02-15-preview\"\n",
    ")\n",
    "\n",
    "CHAT_COMPLETIONS_MODEL = \"gpt-4o-mini\"\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d571692-e053-4221-8fd3-fbfd0799a530",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Parameter: max_tokens\n",
    "**Description**: The maximum number of tokens to generate in the completion. \\\n",
    "**Default**: 16 \\\n",
    "**Example**: max_tokens=50\n",
    "\n",
    "The token count of your prompt plus max_tokens can't exceed the model's context length. \\\n",
    "Most models have a context length of 2048 tokens (except for the newest models, which support 4096). Please refer to documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fa05011-da98-43f5-8655-091991443dd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Tokens: 16\n\nThe best pet can vary greatly depending on individual preferences, lifestyle, and living situation\n\n--------------------------------------------------------------------------------\n\nMax Tokens: 32\n\nThe best pet can vary greatly depending on individual preferences, lifestyles, and living situations. Here are a few popular options:\n\n1. **Dogs**: Known for\n\n--------------------------------------------------------------------------------\n\nMax Tokens: 60\n\nThe best pet can vary greatly depending on individual preferences, lifestyle, and living situation. Here are a few popular options along with what makes them special:\n\n1. **Dogs**: Often considered \"man's best friend,\" dogs are loyal, affectionate, and can be great companions. They require regular exercise and\n\n--------------------------------------------------------------------------------\n\nMax Tokens: 100\n\nThe best pet often depends on a person's lifestyle, preferences, and needs. Here are a few popular options, each with its own merits:\n\n1. **Dogs**: Known for their loyalty and companionship, dogs can provide love, protection, and an active lifestyle. They often require more attention, exercise, and training.\n\n2. **Cats**: Cats are independent animals that typically require less maintenance than dogs. They can be affectionate and playful companions, making them a great choice for busy individuals.\n\n3\n\n--------------------------------------------------------------------------------\n\n"
     ]
    }
   ],
   "source": [
    "def call_openai_with_max_tokens(max_tokens):\n",
    "    response = client.chat.completions.create(\n",
    "          model=\"gpt-4o-mini\",\n",
    "          messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "                    {\"role\":\"user\",\"content\": \"The best pet is a\"}],\n",
    "                    max_tokens=max_tokens\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Generate with different presence_penalty values\n",
    "penalties = [16, 32, 60, 100]\n",
    "for penalty in penalties:\n",
    "    print(f\"Max Tokens: {penalty}\\n\")\n",
    "    print(call_openai_with_max_tokens(penalty))\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec1b9f9e-2ace-402a-94e2-5b0f7a7a413a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Parameter: temperature\n",
    "\n",
    "**Description**: Controls the randomness of the output. Lower values make the output more deterministic, while higher values increase randomness. \\\n",
    "**Value Range**: 0 to 1 \\\n",
    "**Default Value**: 1 \\\n",
    "**Example**: temperature=0.7\n",
    "\n",
    "Higher values means the model will take more risks. \\\n",
    "Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer.\n",
    "\n",
    "---\n",
    "**NOTE**: We generally recommend altering this or top_p but not both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08b691a1-8248-44f8-8572-76fde6d9af67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def call_openai(num_times, prompt, temperature=0.75, use_seed=False):\n",
    "    for i in range(num_times):\n",
    "        if use_seed:\n",
    "            response = client.chat.completions.create(\n",
    "            model=CHAT_COMPLETIONS_MODEL,\n",
    "            messages = [{\"role\":\"system\", \"content\":\"Eres un asistente zombie\"}],\n",
    "                     max_tokens=60,\n",
    "                    seed=SEED,\n",
    "                    temperature = 0\n",
    "    )\n",
    "        else:\n",
    "            response = client.chat.completions.create(\n",
    "                model= CHAT_COMPLETIONS_MODEL,\n",
    "                messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"}],\n",
    "                    max_tokens=60,\n",
    "                    temperature = 1\n",
    "            )\n",
    "        print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a523dad4-3b87-46bf-8e1d-2effae76f5b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I assist you today?\nHow can I assist you today?\nHow can I assist you today?\nHow can I assist you today?\nHow can I assist you today?\nHow can I assist you today?\nHow can I assist you today?\nHow can I assist you today?\nHow may I assist you today?\nHow can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Without seed and temperature, the response is different each time\n",
    "call_openai(10, 'The best pet is a ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9115f52-356a-4aa0-874a-628e59d13e5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Grrr! Soy un asistente zombie, listo para ayudarte con tus preguntas. ¿Qué necesitas? Grrr...\n¡Grrr! Soy un asistente zombie, listo para ayudarte con tus preguntas. Aunque mi cerebro está un poco... lento, haré lo posible por responderte. ¿Qué necesitas? Grrr...\n¡Grrr! Cerebros... ¿En qué puedo ayudarte hoy?\n¡Grrr! Cerebros... ¿En qué puedo ayudarte hoy?\n¡Grrr! Cerebros... ¿En qué puedo ayudarte hoy?\n¡Grrr! Soy un asistente zombie, listo para ayudarte con tus preguntas. Aunque mi cerebro está un poco... lento, haré lo mejor que pueda. ¿Qué necesitas? Grrr...\n¡Grrr! Soy un asistente zombie, listo para ayudarte con tus preguntas. Aunque mi cerebro está un poco... lento, haré lo posible por responderte. ¿Qué necesitas? Grrr...\n¡Grrr! Cerebros... ¿En qué puedo ayudarte hoy?\n¡Grrr! Cerebros... ¿En qué puedo ayudarte hoy?\n¡Grrr! Cerebros... ¿En qué puedo ayudarte hoy?\n"
     ]
    }
   ],
   "source": [
    "# Now using a seed and 0 temperature, the response is the much more consisitent\n",
    "call_openai(10, 'The best pet is a ', temperature = 0, use_seed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb27675b-39e9-4352-a757-15fc18ef5ee1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Parameter: n\n",
    "**Description**: Specifies the number of completions to generate for each prompt. \\\n",
    "**Default Value**: 1 \\\n",
    "**Example**: n = 3 \n",
    "\n",
    "---\n",
    "**Note**: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bb6095e-a66d-414f-b9e8-f1dd5874964e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ¡Grrr! Cerebros... ¿En qué puedo ayudarte hoy?\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "            model=CHAT_COMPLETIONS_MODEL,\n",
    "            messages = [{\"role\":\"system\", \"content\":\"Eres un asistente zombie\"}],\n",
    "                     max_tokens=60,\n",
    "                    seed=SEED,\n",
    "                    temperature = 0\n",
    "    )\n",
    "\n",
    "for index, c in enumerate(response.choices):\n",
    "    print(index, c.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69b25de3-40c0-4b54-a575-483d3bba4620",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Parameter: presence_penalty\n",
    "**Description**: Penalizes new tokens based on whether they appear in the text so far, encouraging the model to use new tokens. \\\n",
    "**Value Range**: -2.0 to 2.0 \\\n",
    "**Default Value**: 0 \\\n",
    "**Example**: presence_penalty=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e5a15ae-9e5b-49cb-9d80-b98a57efdb57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presence Penalty: 0\n\nThe best pet often depends on individual preferences, lifestyle, and living situation. Here are a few popular options:\n\n1. **Dogs**: Known for their loyalty and companionship, dogs make great pets for active individuals and families. They require regular exercise and attention.\n\n2. **Cats**: Cats are\n\n--------------------------------------------------------------------------------\n\nPresence Penalty: 0.5\n\nThe best pet can vary greatly depending on individual preferences, lifestyles, and needs. Some people might consider dogs the best pets due to their loyalty and companionship, while others might prefer cats for their independence and low maintenance. Small pets like hamsters or guinea pigs can be great for those with limited space,\n\n--------------------------------------------------------------------------------\n\nPresence Penalty: 1.0\n\nThe best pet can vary greatly depending on individual preferences, lifestyles, and living situations. Some people may find that dogs are the best pets because they are loyal, affectionate, and can be great companions. Others might prefer cats for their independence and lower maintenance needs. Small animals like hamsters, guinea pigs\n\n--------------------------------------------------------------------------------\n\nPresence Penalty: 1.5\n\nThe best pet is subjective and varies depending on an individual's lifestyle, preferences, and needs. Some people prefer dogs for their loyalty and companionship, while others may choose cats for their independence and low maintenance. Other popular pets include rabbits, birds, fish, and reptiles, each offering unique benefits. Ultimately,\n\n--------------------------------------------------------------------------------\n\nPresence Penalty: 2.0\n\nThe best pet can vary greatly depending on individual preferences and lifestyles. Some people might argue that dogs are the best pets because they are loyal, affectionate, and great companions. Others may prefer cats for their independence and lower maintenance needs. Additionally, small animals like rabbits, hamsters, or guinea pigs can\n\n--------------------------------------------------------------------------------\n\n"
     ]
    }
   ],
   "source": [
    "def call_openai_with_presence_penalty(presence_penalty):\n",
    "    response = client.chat.completions.create(\n",
    "          model=CHAT_COMPLETIONS_MODEL,\n",
    "          messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "                    {\"role\":\"user\",\"content\": \"The best pet is a\"}],\n",
    "                    max_tokens=60,\n",
    "                    presence_penalty= 0.6\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Generate with different presence_penalty values\n",
    "penalties = [0, 0.5, 1.0, 1.5, 2.0]\n",
    "for penalty in penalties:\n",
    "    print(f\"Presence Penalty: {penalty}\\n\")\n",
    "    print(call_openai_with_presence_penalty(penalty))\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8595c472-f776-45e8-9d0c-e7e2a07a08ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Parameter: frequency_penalty\n",
    "**Description**: Penalizes new tokens based on their existing frequency in the text so far, reducing the likelihood of repeating the same line verbatim. \\\n",
    "**Value Range**: -2.0 to 2.0 \\\n",
    "**Default Value**: 0 \\\n",
    "**Example**: frequency_penalty=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64ce7c8e-433e-4d8c-b987-93a36b55cff0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Use cases to explore\n",
    "1. **Compare Responses** \\\n",
    "Generate multiple completions to compare and choose the best response for your use case.\n",
    "\n",
    "2. **Increase Diversity** \\\n",
    "Use multiple completions to get a variety of responses, which is useful in creative applications.\n",
    "\n",
    "3. **Enhance Robustness** \\\n",
    "Generate multiple responses to ensure consistency and accuracy across different completions.\n",
    "\n",
    "#### Best Practices\n",
    "1. **Optimize Prompt Length** \\\n",
    "Keep your prompts concise but informative to ensure the model has enough context.\n",
    "\n",
    "2. **Adjust Temperature and Top_p** \\\n",
    "Use these parameters to balance between deterministic and creative responses.\n",
    "\n",
    "3. **Monitor Token Usage** \\\n",
    "Be mindful of the max_tokens parameter to manage costs and response length.\n",
    "\n",
    "4. **Use Stopping Sequences** \\\n",
    "Define stopping sequences to control where the model should stop generating text, ensuring the output is within the desired context.\n",
    "\n",
    "5. **Generate Multiple Completions** \\\n",
    "Use the n parameter to generate multiple completions and select the best one for your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66cc694d-5171-41dc-b760-250c19b846ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Exercise 1: Exploring 'top_p' Parameter\n",
    "### Description:\n",
    "- The 'top_p' parameter controls nucleus sampling. Lower values make the output more focused by limiting the pool of tokens.\n",
    "\n",
    "### Task:\n",
    "- Write a function that calls the model with different 'top_p' values and observe how the output changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b2945df-33b5-4503-b632-6bd6f054a7ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top P: 0.1\n\nExercise offers a multitude of benefits that span physical, mental, and emotional health. Here are some key advantages:\n\n### Physical Health Benefits:\n1. **Improved Cardiovascular Health**: Regular exercise strengthens the heart, improves circulation, and lowers the risk of heart disease and stroke.\n2. **Weight\n\n--------------------------------------------------------------------------------\n\nTop P: 0.3\n\nExercise offers a multitude of benefits for both physical and mental well-being. Here are some key advantages:\n\n### Physical Health Benefits:\n1. **Cardiovascular Health**: Regular exercise strengthens the heart, improves circulation, and helps lower blood pressure and cholesterol levels, reducing the risk of heart disease.\n\n2\n\n--------------------------------------------------------------------------------\n\nTop P: 0.7\n\nExercise offers a wide array of benefits for both physical and mental health. Here are some of the key advantages:\n\n### Physical Benefits:\n\n1. **Improved Cardiovascular Health:** Regular exercise strengthens the heart muscle, improves circulation, and lowers blood pressure, reducing the risk of heart disease.\n\n2. **\n\n--------------------------------------------------------------------------------\n\nTop P: 1.0\n\nExercise offers a wide range of physical, mental, and emotional benefits that contribute to overall health and well-being. Here are some key advantages:\n\n### Physical Benefits:\n1. **Improved Cardiovascular Health**: Regular exercise strengthens the heart, improves circulation, and can lower blood pressure and cholesterol levels.\n\n\n--------------------------------------------------------------------------------\n\n"
     ]
    }
   ],
   "source": [
    "def call_openai_with_top_p(top_p):\n",
    "    response = client.chat.completions.create(\n",
    "          model= CHAT_COMPLETIONS_MODEL,\n",
    "          messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "                    {\"role\":\"user\",\"content\": \"Describe the benefits of exercise.\"}],\n",
    "                    max_tokens=60,\n",
    "                    top_p= 1\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Try with different values of top_p\n",
    "top_p_values = [0.1, 0.3, 0.7, 1.0]\n",
    "for value in top_p_values:\n",
    "    print(f\"Top P: {value}\\n\")\n",
    "    print(call_openai_with_top_p(value))\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e54dc266-9ccc-4ed2-94fa-b4c20f3db881",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Exercise 2: Frequency Penalty Exploration\n",
    "### Description:\n",
    "- This exercise will explore how the 'frequency_penalty' parameter affects the model's tendency to repeat itself.\n",
    "\n",
    "### Task:\n",
    "- Generate completions using different frequency_penalty values and note the diversity in responses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf034c00-47fd-40dd-aca4-8860ca32329d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency Penalty: -1.0\n\nOne fun fact about space is that it is completely silent! Unlike on Earth, where sound waves travel through air or water, space is a vacuum, meaning there are very few particles to carry sound waves. So if you were floating in space without a spacesuit, you wouldn't be able to hear anything\n\n--------------------------------------------------------------------------------\n\nFrequency Penalty: 0.0\n\nA fun fact about space is that it is completely silent! Unlike on Earth, where sound travels through air (or other mediums), space is a vacuum, meaning there are very few particles to carry sound waves. So if you were in space and tried to shout, no one would be able to hear\n\n--------------------------------------------------------------------------------\n\nFrequency Penalty: 1.0\n\nA fun fact about space is that a day on Venus is longer than a year on Venus! Venus has an extremely slow rotation on its axis, taking about 243 Earth days to complete one full rotation. However, it orbits the Sun in about 225 Earth days, meaning that it takes longer\n\n--------------------------------------------------------------------------------\n\nFrequency Penalty: 2.0\n\nA fun fact about space is that there are more stars in the universe than grains of sand on all the beaches on Earth! It's estimated that there are about 100 billion to 200 billion galaxies, each containing millions or even billions of stars, which adds up to an incomprehensible number. This\n\n--------------------------------------------------------------------------------\n\n"
     ]
    }
   ],
   "source": [
    "def call_openai_with_frequency_penalty(frequency_penalty):\n",
    "    response = client.chat.completions.create(\n",
    "          model=CHAT_COMPLETIONS_MODEL,\n",
    "          messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "                    {\"role\":\"user\",\"content\": \"Tell me a fun fact about space.\"}],\n",
    "                    max_tokens=60,\n",
    "                    frequency_penalty= 0.3\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "penalties = [-1.0, 0.0, 1.0, 2.0]\n",
    "for penalty in penalties:\n",
    "    print(f\"Frequency Penalty: {penalty}\\n\")\n",
    "    print(call_openai_with_frequency_penalty(penalty))\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74bc3256-1224-49f4-9288-4ec5e8538b39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Exercise 3: Multi-Completion with 'n' Parameter\n",
    "### Description:\n",
    "- This exercise will help students generate multiple completions for the same prompt and compare the results.\n",
    "\n",
    "### Task:\n",
    "- Generate 3 completions for the same prompt by adjusting the 'n' parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef44a625-919d-4e15-8448-9c72125da029",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 One fun fact about space is that there are more stars in the universe than there are grains of sand on all the beaches on Earth! Scientists estimate that there are about 100 billion to 200 billion galaxies in the observable universe, each containing billions of stars, making the total number of stars truly astronomical\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "          model=CHAT_COMPLETIONS_MODEL,\n",
    "          messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "                    {\"role\":\"user\",\"content\": \"Tell me a fun fact about space.\"}],\n",
    "                    max_tokens=60,\n",
    "                    frequency_penalty= 0.3\n",
    "    )\n",
    "\n",
    "for index, c in enumerate(response.choices):\n",
    "    print(index, c.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a258d56-bee3-4550-8cc0-bc06234455fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Exercise 4: Temperature vs. Deterministic Output\n",
    "### Description:\n",
    "- Adjust the 'temperature' parameter to explore the balance between creative and deterministic responses.\n",
    "\n",
    "### Task:\n",
    "- Generate completions with different temperature values and analyze the variance in output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e81c6a41-9c0f-41f3-8036-8f2e24504070",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature: 0.0\n\nSure! Here are some name suggestions for your new tech startup:\n\n1. **TechTide**\n2. **InnovateX**\n3. **\n\n--------------------------------------------------------------------------------\n\nTemperature: 0.3\n\nSure! Here are some name suggestions for your tech startup:\n\n1. **InnoVate**\n2. **TechNexus**\n3. **\n\n--------------------------------------------------------------------------------\n\nTemperature: 0.7\n\nSure! Here are some suggestions for a tech startup name:\n\n1. **TechNova**\n2. **InnoVibe**\n3. **Byte\n\n--------------------------------------------------------------------------------\n\nTemperature: 1.0\n\nSure! Here are some suggestions for a tech startup name:\n\n1. **TechNexus**\n2. **InnovaSphere**\n3. **Byte\n\n--------------------------------------------------------------------------------\n\n"
     ]
    }
   ],
   "source": [
    "def call_openai_with_temperature(temperature):\n",
    "    response = client.chat.completions.create(\n",
    "          model=CHAT_COMPLETIONS_MODEL,\n",
    "          messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "                    {\"role\":\"user\",\"content\": \"Suggest a name for a new tech startup.\"}],\n",
    "                    max_tokens=30,\n",
    "                    temperature= 0.5\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "temperatures = [0.0, 0.3, 0.7, 1.0]\n",
    "for temp in temperatures:\n",
    "    print(f\"Temperature: {temp}\\n\")\n",
    "    print(call_openai_with_temperature(temp))\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_OpenAI_parameters",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
