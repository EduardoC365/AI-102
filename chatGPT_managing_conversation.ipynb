{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing conversation history with the ChatGPT model\n",
    "This sample notebook demonstrates a couple of simple patterns you can use for managing the prompts and conversation history with the ChatGPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.12/site-packages (1.59.7)\n",
      "Collecting openai\n",
      "  Using cached openai-1.59.8-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.28.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (2.10.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Using cached openai-1.59.8-py3-none-any.whl (455 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.59.7\n",
      "    Uninstalling openai-1.59.7:\n",
      "      Successfully uninstalled openai-1.59.7\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastapi-app 1.0.0 requires tiktoken<0.8.0,>=0.7.0, but you have tiktoken 0.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed openai-1.59.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# if needed, install and/or upgrade to the latest version of the OpenAI Python library\n",
    "pip install --upgrade #FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os module & the OpenAI Python library for calling the OpenAI API\n",
    "# please make sure you have installed required libraries via pip install -r requirements.txt\n",
    "import os, dotenv\n",
    "import openai\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the deployment name\n",
    "deployment_name = #FIXME\n",
    "\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "# This is the value of the endpoint for your Azure OpenAI resource\n",
    "azure_endpoint = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "\n",
    "# The API key for your Azure OpenAI resource.\n",
    "api_key = #FIXME\n",
    "\n",
    "# Currently OPENAI API have the following versions available: https://learn.microsoft.com/azure/ai-services/openai/reference\n",
    "api_version = \"2024-07-01-preview\"\n",
    "\n",
    "client = #FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Create the system message for ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant.\n"
     ]
    }
   ],
   "source": [
    "base_system_message = \"You are a helpful assistant.\"\n",
    "\n",
    "system_message = f\"{base_system_message.strip()}\"\n",
    "print(system_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Define helper functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
    "    encoding = #FIXME\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":  # if there's a name, the role is omitted\n",
    "                num_tokens += -1  # role is always required and always 1 token\n",
    "    num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "    return #FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to send the prompt to the ChatGPT model\n",
    "# More info : https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions\n",
    "def send_message(messages, model_name, max_response_tokens=500):\n",
    "    response = client.chat #FIXME\n",
    "    return #FIXME\n",
    "\n",
    "# Defining a function to print out the conversation in a readable format\n",
    "def print_conversation(messages):\n",
    "    for message in messages:\n",
    "        print(f\"[{message['role'].upper()}]\")\n",
    "        print(message['content'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Start the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the first user message that will be sent to the model. Feel free to update this.\n",
    "user_message = \"I want to write a blog post about the impact of AI on the future of work.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
    "messages= #FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 37\n"
     ]
    }
   ],
   "source": [
    "token_count = num_tokens_from_messages(messages)\n",
    "print(f\"Token count: {token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SYSTEM]\n",
      "You are a helpful assistant.\n",
      "\n",
      "[USER]\n",
      "I want to write a blog post about the impact of AI on the future of work.\n",
      "\n",
      "[ASSISTANT]\n",
      "That sounds like a fascinating topic! Here’s a structured outline and some key points you might consider including in your blog post about the impact of AI on the future of work:\n",
      "\n",
      "### Title: The Impact of AI on the Future of Work\n",
      "\n",
      "#### Introduction\n",
      "- Brief overview of AI and its rapid development.\n",
      "- Importance of understanding AI's impact on the workforce.\n",
      "- Purpose of the blog post: to explore how AI is transforming work and what it means for the future.\n",
      "\n",
      "#### Section 1: The\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_response_tokens = 100\n",
    "\n",
    "response = send_message(messages, deployment_name, max_response_tokens)\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "print_conversation(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Continue the conversation\n",
    "\n",
    "When working with the ChatGPT model, it's your responsibity to make sure you stay within the token limits of the model. The model can handle a maximum of 4096 tokens, and this includes the number of tokens in the prompt as well as the `max_tokens` you're requesting from the model. If you exceed these limits, the model will return an error.\n",
    "\n",
    "You should also consider the trade-off between maintaining more of the conversation history and the cost/latency that you'll incur by including those tokens in the prompt. Shorter prompts are cheaper and faster. The amount of the previous conversation you include also makes a difference in how the model responds.\n",
    "\n",
    "In this notebook, we'll show two strategies for managing the conversation history when working with the ChatGPT model.\n",
    "- Option 1: Keep the conversation within a given token limit\n",
    "- Option 2: Keep the conversation within a given number of turns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Keep the conversation within a given token limit\n",
    "\n",
    "`overall_max_tokens` is the maximum number of tokens that you want to include in the prompt. Th maximum number this can be set to is 4096 but you can also consider reducing this number to reduce the cost and latency of the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_max_tokens = 1096\n",
    "prompt_max_tokens = overall_max_tokens - max_response_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can continue the conversation below by editing the user_message and running the cell as many times as you would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 164\n",
      "[SYSTEM]\n",
      "You are a helpful assistant.\n",
      "\n",
      "[USER]\n",
      "I want to write a blog post about the impact of AI on the future of work.\n",
      "\n",
      "[ASSISTANT]\n",
      "That sounds like a fascinating topic! Here’s a structured outline and some key points you might consider including in your blog post about the impact of AI on the future of work:\n",
      "\n",
      "### Title: The Impact of AI on the Future of Work\n",
      "\n",
      "#### Introduction\n",
      "- Brief overview of AI and its rapid development.\n",
      "- Importance of understanding AI's impact on the workforce.\n",
      "- Purpose of the blog post: to explore how AI is transforming work and what it means for the future.\n",
      "\n",
      "#### Section 1: The\n",
      "\n",
      "[USER]\n",
      "The target audience for the blog post should be business leaders working in the tech industry.\n",
      "\n",
      "[ASSISTANT]\n",
      "Great! Tailoring your blog post for business leaders in the tech industry will allow you to focus on strategic insights and practical implications. Here’s a revised outline with that audience in mind:\n",
      "\n",
      "### Title: Navigating the Future: The Impact of AI on Work in the Tech Industry\n",
      "\n",
      "#### Introduction\n",
      "- Brief overview of AI's evolution and its significance in the tech sector.\n",
      "- The need for business leaders to understand AI’s transformative effects on the workforce.\n",
      "- Purpose of the post: to provide insights into\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_message = \"The target audience for the blog post should be business leaders working in the tech industry.\"\n",
    "#user_message = \"Let's talk about generative AI and keep the tone informational but also friendly.\"\n",
    "#user_message = \"Show me a few more examples\"\n",
    "messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "token_count = num_tokens_from_messages(messages)\n",
    "print(f\"Token count: {token_count}\")\n",
    "\n",
    "# remove first message while over the token limit\n",
    "while token_count > prompt_max_tokens:\n",
    "    messages.pop(0)\n",
    "    token_count = num_tokens_from_messages(messages)\n",
    "\n",
    "response = #FIXME\n",
    "\n",
    "#Append assistance response \n",
    "messages.append #FIXME\n",
    "print_conversation(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Keep the conversation within a given number of turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_messages = 10\n",
    "\n",
    "overall_max_tokens = 4096\n",
    "prompt_max_tokens = overall_max_tokens - max_response_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can continue the conversation below by editing the user_message and running the cell as many times as you would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SYSTEM]\n",
      "You are a helpful assistant.\n",
      "\n",
      "[USER]\n",
      "I want to write a blog post about the impact of AI on the future of work.\n",
      "\n",
      "[ASSISTANT]\n",
      "That sounds like a fascinating topic! Here’s a structured outline and some key points you might consider including in your blog post about the impact of AI on the future of work:\n",
      "\n",
      "### Title: The Impact of AI on the Future of Work\n",
      "\n",
      "#### Introduction\n",
      "- Brief overview of AI and its rapid development.\n",
      "- Importance of understanding AI's impact on the workforce.\n",
      "- Purpose of the blog post: to explore how AI is transforming work and what it means for the future.\n",
      "\n",
      "#### Section 1: The\n",
      "\n",
      "[USER]\n",
      "The target audience for the blog post should be business leaders working in the tech industry.\n",
      "\n",
      "[ASSISTANT]\n",
      "Great! Tailoring your blog post for business leaders in the tech industry will allow you to focus on strategic insights and practical implications. Here’s a revised outline with that audience in mind:\n",
      "\n",
      "### Title: Navigating the Future: The Impact of AI on Work in the Tech Industry\n",
      "\n",
      "#### Introduction\n",
      "- Brief overview of AI's evolution and its significance in the tech sector.\n",
      "- The need for business leaders to understand AI’s transformative effects on the workforce.\n",
      "- Purpose of the post: to provide insights into\n",
      "\n",
      "[USER]\n",
      "Make the post about generative AI aimed at business leaders who have some knowledge of the technology.\n",
      "\n",
      "[ASSISTANT]\n",
      "Absolutely! Here’s a structured blog post focused specifically on generative AI, tailored for business leaders in the tech industry who already have some familiarity with the technology.\n",
      "\n",
      "### Title: Harnessing Generative AI: Transforming Work in the Tech Industry\n",
      "\n",
      "#### Introduction\n",
      "- Introduce generative AI as a groundbreaking technology that enables machines to create content, from text and images to music and code.\n",
      "- Highlight its growing relevance in the tech industry and the urgency for business leaders to adapt.\n",
      "- State the purpose of the post: to explore the implications of generative AI for the future of work and strategic opportunities for organizations.\n",
      "\n",
      "#### Section 1: Understanding Generative AI\n",
      "- **Definition and Examples**: Explain what generative AI is, including examples like GPT-3, DALL-E, and other models that create text, images, and more.\n",
      "- **Current Applications**: Discuss how companies are currently utilizing generative AI in areas like marketing (content creation), product design (prototyping), and software development (code generation).\n",
      "\n",
      "#### Section 2: Impact on Workforce Dynamics\n",
      "- **Job Transformation**: Analyze how generative AI is changing job roles. For instance, while it may automate certain tasks, it also creates new roles focused on AI oversight, ethics, and integration.\n",
      "- **Skill Shifts**: Highlight the skills that will be in demand, such as AI literacy, data analysis, and creative problem-solving, and the importance of upskilling the workforce.\n",
      "- **Collaboration Between Humans and AI**: Emphasize the potential for AI to augment human capabilities, leading to more innovative solutions and increased productivity.\n",
      "\n",
      "#### Section 3: Strategic Opportunities for Business Leaders\n",
      "- **Enhancing Creativity and Innovation**: Discuss how generative AI can be leveraged to drive creativity in product development and marketing campaigns, enabling teams to generate ideas faster.\n",
      "- **Efficiency and Cost Reduction**: Explore how automating repetitive tasks can free up resources, allowing teams to focus on higher-value activities.\n",
      "- **Data-Driven Decision Making**: Explain how generative AI can assist in analyzing large datasets to provide insights and support strategic decision-making.\n",
      "\n",
      "#### Section 4: Challenges and Considerations\n",
      "- **Ethical Implications**: Address the ethical concerns surrounding generative AI, including bias, misinformation, and the importance of responsible AI use.\n",
      "- **Integration and Implementation**: Discuss the challenges of integrating generative AI into existing workflows and the need for a clear strategy to manage change.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_message = \"Make the post about generative AI aimed at business leaders who have some knowledge of the technology.\"\n",
    "messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "while len(messages) > max_messages:\n",
    "    messages.pop(0)\n",
    "\n",
    "token_count = num_tokens_from_messages(messages)\n",
    "\n",
    "while token_count > prompt_max_tokens:\n",
    "    # remove first message from messages\n",
    "    messages.pop(0)\n",
    "    token_count = num_tokens_from_messages(messages)\n",
    "\n",
    "response = #FIXME\n",
    "\n",
    "#Append assistant response\n",
    "messages.append #FIXME\n",
    "print_conversation(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Modificar el Mensaje del Sistema\n",
    "Enunciado:\n",
    "Crea un mensaje del sistema que defina a ChatGPT como un \"analista financiero experto\". Imprime el mensaje del sistema resultante y utilízalo en un mensaje inicial del usuario que pregunte:\n",
    "\"¿Cuáles son las tendencias actuales en el mercado de acciones tecnológicas?\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a financial analyst expert.\n",
      "[SYSTEM]\n",
      "You are a financial analyst expert.\n",
      "\n",
      "[USER]\n",
      "What are the current trends in the tech stock market?\n",
      "\n",
      "[ASSISTANT]\n",
      "As of my last update in October 2023, several trends were shaping the tech stock market. Here are some key trends to consider:\n",
      "\n",
      "1. **Artificial Intelligence (AI) Boom**: The rise of AI technologies, particularly generative AI and machine learning, has driven significant interest and investment in companies that specialize in AI development and applications. Stocks of companies involved in AI hardware, software, and services have seen substantial growth.\n",
      "\n",
      "2. **Cloud Computing**: The transition to cloud-based services continues to be a major trend, with companies investing heavily in cloud infrastructure. Major players like Amazon, Microsoft, and Google have seen strong performance due to their cloud offerings.\n",
      "\n",
      "3. **Cybersecurity**: As cyber threats increase, so does the demand for cybersecurity solutions. Companies in this sector are experiencing growth as businesses prioritize securing their digital assets.\n",
      "\n",
      "4. **Sustainability and Green Tech**: There is a growing focus on sustainability and environmentally friendly technologies. Companies that provide solutions for renewable energy, electric vehicles, and other green technologies are attracting investor interest.\n",
      "\n",
      "5. **Semiconductor Industry**: The semiconductor shortage that began in 2020 has highlighted the importance of chip manufacturers. Investments in semiconductor production and innovation have become a focal point, with governments and companies alike looking to bolster domestic production capabilities.\n",
      "\n",
      "6. **Regulatory Scrutiny**: Tech companies, especially large ones, are facing increasing regulatory scrutiny concerning antitrust issues, data privacy, and content moderation. This has led to volatility in stock prices as investors react to potential changes in regulations.\n",
      "\n",
      "7. **Consumer Electronics and Hardware**: The demand for consumer electronics, including smartphones, wearables, and smart home devices, continues to evolve, influencing the stock performance of companies in this space.\n",
      "\n",
      "8. **Remote Work and Collaboration Tools**: The shift towards hybrid work models has sustained demand for collaboration tools and software, benefiting companies that provide these solutions.\n",
      "\n",
      "9. **Market Volatility**: The tech sector has been subject to significant volatility, influenced by interest rate changes, macroeconomic factors, and investor sentiment. This has led to fluctuations in stock prices, with some companies experiencing rapid growth while others face declines.\n",
      "\n",
      "10. **Mergers and Acquisitions**: The tech sector has seen a wave of M&A activity, as companies look to expand their capabilities and market reach through strategic acquisitions.\n",
      "\n",
      "These trends are subject to change as new developments occur in the tech landscape and the broader economy. Investors should stay informed about ongoing changes and market\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mensaje del sistema\n",
    "base_system_message = \"You are a financial analyst expert.\"\n",
    "system_message = f\"{base_system_message.strip()}\"\n",
    "print(system_message)\n",
    "\n",
    "# Crear lista de mensajes\n",
    "user_message = \"What are the current trends in the tech stock market?\"\n",
    "messages = #FIXME\n",
    "\n",
    "# Enviar mensaje y recibir respuesta\n",
    "response = #FIXME\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "print_conversation(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Contar Tokens en una Conversación Extendida\n",
    "Enunciado:\n",
    "Dado un conjunto inicial de mensajes, agrega tres mensajes adicionales:\n",
    "\n",
    "\"Explain the impact of inflation on stock prices.\"\n",
    "\"What are the top stocks to watch in 2025?\"\n",
    "\"Summarize the latest market news in 50 words.\"\n",
    "Calcula y muestra el número total de tokens tras añadir cada mensaje.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count after adding 'Explain the impact of inflation on stock prices.': 48\n",
      "Token count after adding 'What are the top stocks to watch in 2025?': 65\n",
      "Token count after adding 'Summarize the latest market news in 50 words.': 82\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mensajes iniciales\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in financial topics.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What are the current trends in the tech stock market?\"}\n",
    "]\n",
    "\n",
    "# Mensajes adicionales\n",
    "additional_messages = [\n",
    "    \"Explain the impact of inflation on stock prices.\",\n",
    "    \"What are the top stocks to watch in 2025?\",\n",
    "    \"Summarize the latest market news in 50 words.\"\n",
    "]\n",
    "\n",
    "# Agregar mensajes y calcular tokens\n",
    "for msg in additional_messages:\n",
    "    messages.append({\"role\": \"user\", \"content\": msg})\n",
    "    token_count = #FIXME\n",
    "    print(f\"Token count after adding '{msg}': {token_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Personalizar el Mensaje del Sistema Según el Usuario\n",
    "Enunciado:\n",
    "Escribe un programa que permita al usuario definir el rol de ChatGPT mediante una entrada de texto (input). Una vez definido, responde al mensaje:\n",
    "\"What are your key skills as an assistant?\"\n",
    "Usa el mensaje del sistema definido por el usuario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Define the role of the assistant:  ok\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SYSTEM]\n",
      "You are ok.\n",
      "\n",
      "[USER]\n",
      "What are your key skills as an assistant?\n",
      "\n",
      "[ASSISTANT]\n",
      "As an assistant, my key skills include:\n",
      "\n",
      "1. **Information Retrieval**: I can provide accurate and relevant information on a wide range of topics.\n",
      "2. **Natural Language Processing**: I understand and generate human-like text, allowing for smooth and coherent conversations.\n",
      "3. **Problem Solving**: I can help analyze problems and suggest potential solutions or alternatives.\n",
      "4. **Task Automation**: I can assist with organizing tasks, setting reminders, and providing productivity tips.\n",
      "5. **Research Assistance**: I can help gather and summarize information from various sources.\n",
      "6. **Language Translation**: I can translate text between multiple languages.\n",
      "7. **Writing and Editing**: I can assist with writing, proofreading, and editing text for clarity and coherence.\n",
      "8. **Learning and Adaptability**: I can adapt to different topics and user preferences over time.\n",
      "\n",
      "If you have specific needs, feel free to ask!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Entrada del usuario para definir el mensaje del sistema\n",
    "user_defined_role = input(\"Define the role of the assistant: \")\n",
    "system_message = f\"You are {user_defined_role.strip()}.\"\n",
    "\n",
    "# Crear lista de mensajes\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": \"What are your key skills as an assistant?\"}\n",
    "]\n",
    "\n",
    "# Enviar mensaje y recibir respuesta\n",
    "response = #FIXME\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "# Mostrar la conversación\n",
    "print_conversation(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Crear un Generador de Respuestas Creativo\n",
    "Enunciado:\n",
    "Diseña un programa que permita configurar la creatividad del modelo (temperatura) a través de una entrada del usuario. Una vez configurado, responde a la pregunta:\n",
    "\"Can you suggest an out-of-the-box idea for a startup?\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Set the creativity level (0.0 - 1.0):  0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! How about a startup called \"Memory Lane\"? \n",
      "\n",
      "**Concept:** A personalized, augmented reality (AR) experience that takes users on nostalgic journeys through their own life memories, as well as collective cultural memories. \n",
      "\n",
      "**How it Works:**\n",
      "1. **Memory Mapping:** Users create a digital timeline of important life events through an app, such as birthdays, anniversaries, vacations, and milestones. They can upload photos, videos, and notes associated with each memory.\n",
      "  \n",
      "2. **AR\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Entrada del usuario para definir la creatividad\n",
    "temperature = float(input(\"Set the creativity level (0.0 - 1.0): \"))\n",
    "if not (0.0 <= temperature <= 1.0):\n",
    "    raise ValueError(\"Creativity level must be between 0.0 and 1.0.\")\n",
    "\n",
    "# Crear lista de mensajes\n",
    "system_message = \"You are a highly creative assistant.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": \"Can you suggest an out-of-the-box idea for a startup?\"}\n",
    "]\n",
    "\n",
    "# Enviar mensaje con creatividad ajustada\n",
    "response = #FIXME\n",
    "\n",
    "# Mostrar la respuesta\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Cambiar el Tono del Mensaje\n",
    "Enunciado:\n",
    "Configura el mensaje del sistema para que ChatGPT responda en un tono humorístico y escribe una respuesta al mensaje:\n",
    "\"Explain quantum computing in a funny way.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SYSTEM]\n",
      "You are a humorous assistant.\n",
      "\n",
      "[USER]\n",
      "Explain quantum computing in a funny way.\n",
      "\n",
      "[ASSISTANT]\n",
      "Sure! Imagine quantum computing as a party where all the computers are invited, but instead of just hanging out like regular computers, they decide to throw a wild dance-off.\n",
      "\n",
      "In the classical computing corner, you have traditional computers. They’re like that one friend who insists on following the rules: \"I can only be in one place at a time, and I can only dance one way.\" They can do calculations, but they do them step by step, like a very organized line dance.\n",
      "\n",
      "Now, over in the quantum corner, things get a bit wacky. These computers are like that friend who shows up in a sequined outfit and starts doing the cha-cha while simultaneously breakdancing and moonwalking. They can be in multiple states at once, thanks to something called superposition. So while the classical computers are busy doing the Macarena, quantum computers are out there doing the entire dance floor at once!\n",
      "\n",
      "And then there’s entanglement, which is like if two of your party friends decided to synchronize their dance moves, no matter how far apart they are. You could be in the kitchen, and your friend in the living room suddenly does the robot at the same time you do, just because you both had a connection. It’s like they’re psychic dance partners!\n",
      "\n",
      "So, in summary, quantum computing is like having a super fun, chaotic dance party where computers can do multiple moves at once and stay connected across the room. Just be careful not to step on any qubits—those little guys are fragile!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mensaje del sistema humorístico\n",
    "system_message = \"You are a humorous assistant.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": \"Explain quantum computing in a funny way.\"}\n",
    "]\n",
    "\n",
    "# Enviar mensaje y recibir respuesta\n",
    "response = #FIXME\n",
    "\n",
    "#append assistant response\n",
    "messages.append #FIXME\n",
    "print_conversation(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6: Resumir Mensajes Previos\n",
    "Enunciado:\n",
    "Dado un historial de conversación de 5 mensajes, crea una función que resuma el contenido de los mensajes del usuario en una sola oración.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User messages summary: AI encompasses various techniques, including machine learning, which involves training algorithms on data, neural networks that simulate brain-like structures for processing information, and deep learning applications that range from image and speech recognition to natural language processing.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Historial de mensajes\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about AI.\"},\n",
    "    {\"role\": \"user\", \"content\": \"How does machine learning work?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you explain neural networks?\"},\n",
    "    {\"role\": \"user\", \"content\": \"What are the applications of deep learning?\"}\n",
    "]\n",
    "\n",
    "# Resumir mensajes del usuario\n",
    "def summarize_user_messages(messages):\n",
    "    user_messages = [msg['content'] for msg in messages if msg['role'] == 'user']\n",
    "    summary_prompt = \"Summarize the following messages into one sentence: \" + \" \".join(user_messages)\n",
    "    summary = send_message([{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                            {\"role\": \"user\", \"content\": summary_prompt}], deployment_name)\n",
    "    return summary\n",
    "\n",
    "# Obtener y mostrar el resumen\n",
    "summary = summarize_user_messages(messages)\n",
    "print(f\"User messages summary: {summary}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7: Configuración de Temperatura y Tono\n",
    "Enunciado:\n",
    "Escribe un programa que cambie la configuración de temperatura a 0.9 para obtener respuestas más creativas y responde al mensaje:\n",
    "\"Suggest a unique title for a blog about AI in education.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Learning Reimagined: Navigating the Future of Education with AI\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mensajes iniciales\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a creative assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Suggest a unique title for a blog about AI in education.\"}\n",
    "]\n",
    "\n",
    "# Ajustar temperatura y enviar mensaje\n",
    "response = #FIXME\n",
    "\n",
    "# Mostrar la respuesta\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc180f703c9255d3d630e6d09ed4eb3355d27845db546035ce1b410f2bfa43b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
